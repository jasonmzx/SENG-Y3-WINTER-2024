# CPU Scheduling

**CPU - I/O Burst Cycle:**

A CPU burst is a period during which a program is using the CPU intensively before it stops to wait for some I/O operation (like reading from disk) or is preempted by the operating system to give time to another program

![OS72](./static/OS_72.png)

![OS72](./static/OS_73.png)

When CPU is **IDLE**, The **Short-Term Scheduler (CPU Sched.)** selects from processes in the Ready Queue, and allocates CPU 
- Queue of PCB (Process Control Blocks), implemented with some of these:
        - FIFO Queue
        - Priority Queue
        - Tree
        - Unordered Linked List

![OS72](./static/OS_74.png)

### Pre-Emptive Scheduling

To Pre-empt, is to interrupt whatever is running, and switch it out with the new process in execution (Hot swapping currently running stuff out, systematically)

1. When a process switches from running to ready state
- Process can be pre-empted, stopping execution of `running` into the `ready` state, it's ready to be continued executing after pre-emption is resolved!

2.  When a process switches from waiting to ready
- When it finishes an I/O operation, resume it's operation by pre-empting some lower priority executing *(Do step 1. fo that)*

**Disadvantages**:

*Can result in race conditions:*
- Consider the case of two processes that share data.
Â» While one process is updating the data is been pre-empted, then the data is in inconsistent state
- **Consider preemption while in kernel mode**: The kernel may be executing a system call that needs to modify some important data structure (queue), what will happen if the process been served is preempted during this system call. *(Race Condition, Data Corruption and larger problems possibly)*


### NON-Pre-Emptive Scheduling

Once CPU is Allocated to Process, it will run it until the process switches into a waiting state

1. Process switches from Running to Waiting State
- `I/O Request` or `Wait()` call on process idling it, so the scheduler can now run another process in ready queue

2. Process Terminates
- Now that the process is over, run another process in ready queue

## Dispatcher:

The dispatcher is a component of the operating system that manages the process of switching the CPU from one process to another. This process is also known as a context switch. Here are some more technical notes about the dispatcher and its role in scheduling within operating systems:

### Context Switching
- **Saving and Restoring Context**: The dispatcher saves the state (context) of the currently running process, so it can be resumed later. The context typically includes the program counter, registers, and memory states.
- **Efficiency**: The context switching process should be efficient because high overhead can lead to significant inefficiencies, especially in systems with many short processes.
- **State Information**: The state of a process is typically stored in the Process Control Block (PCB).

### Transition to User Mode
- **Mode Switching**: Modern operating systems operate in at least two modes: kernel mode and user mode. The dispatcher switches the CPU to user mode before executing a process, as processes run in user mode for security and stability reasons.
- **Protection**: By switching to user mode, the operating system ensures that the process cannot perform harmful operations or access restricted areas of memory.

### Jumping to the Program Counter
- **Program Resumption**: The dispatcher moves the program counter to the location where the process was last interrupted, allowing it to resume execution from the correct place.
- **Instruction State**: The process must resume with the CPU's instruction register set to the next instruction to be executed.

### Dispatch Latency
- **Definition**: Dispatch latency is the time it takes for the dispatcher to switch context, switch to user mode, and jump to the correct location in the user program.
- **Performance Impact**: Dispatch latency is a critical component of system performance. The shorter the latency, the more responsive the system can appear to be.
- **Optimization**: The dispatch latency is often optimized by minimizing the amount of state information that needs to be changed or by using hardware support for context switching.

### Scheduler Interaction
- **Short-term Scheduler**: The dispatcher works closely with the short-term scheduler (also known as the CPU scheduler). The scheduler decides which process to run next, and the dispatcher carries out that decision.
- **Preemption**: In preemptive scheduling, the dispatcher may be invoked when an executing process is interrupted to switch to a higher priority process.

### Additional Considerations
- **Hardware Support**: Some CPUs provide hardware support for switching context, which can significantly reduce dispatch latency.
- **Cache Implications**: Frequent context switches can lead to cache thrashing where the cache is constantly being loaded with new data, reducing cache efficiency.
- **System Calls and Interrupts**: The dispatcher is also involved when handling system calls and interrupts, where a switch from user mode to kernel mode is required, and vice versa.

In summary, the dispatcher is critical in ensuring that the CPU can be efficiently and safely shared among processes. It must work quickly and efficiently to maintain system performance and responsiveness, particularly in systems with high levels of concurrency and frequent context switches.

TODO: 10-52 L6